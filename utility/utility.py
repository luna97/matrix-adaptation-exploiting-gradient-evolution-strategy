import torch
import numpy as np
from deap import base, creator, tools, algorithms
import matplotlib.pyplot as plt
import numpy as np
import random
from scipy.special import gamma
from bisect import bisect_right


class Evaluator:
    """ Class to evaluate the individuals, this is the loss of the froward forward algorithm """

    def __init__(self, x_pos, x_neg, output_size=None):
        """
        Initialize the evaluator
        :param x_pos: positive examples
        :param x_neg: negative examples
        :param output_size: output size of the layer
        """
        self.x_pos = x_pos
        self.x_neg = x_neg
        self.output_size = output_size

    def evaluate(self, individual):
        """
        Evaluate the individual, the fitness is the mean of the squared distance of the positive and negative examples
        """

        input_size = self.x_neg.shape[1] + 1

        if self.output_size is not None:
            # ensure shape of the individual is correct for evaluation
            individual = individual.reshape(self.output_size, input_size)

        # get the weights and bias
        if self.output_size is None:
            bias = individual[-1]
            weights = individual[:-1]
        else:
            bias = individual[:, -1]
            weights = individual[:, :-1]

        # compute the mean of the squared distance for positive and negative examples
        g_pos = self.individual_forward(self.x_pos, weights, bias).pow(2).mean(1)
        g_neg = self.individual_forward(self.x_neg, weights, bias).pow(2).mean(1)

        delta = g_pos - g_neg
        alpha = 4
        delta = -alpha * delta

        # clamp in order to avoid overflow
        delta = delta.clamp(max=88.722)
        exp = torch.exp(delta)

        # clamp in order to avoid overflow
        exp = exp.clamp(min=10e-07, max=1e37)
        loss = torch.log(1 + exp).mean()
        return loss,

    def set_batch(self, x_pos, x_neg):
        """
        Set the batch for the evaluation, used in batched training
        :param x_pos: positive examples
        :param x_neg: negative examples
        """
        self.x_pos = x_pos
        self.x_neg = x_neg

    @staticmethod
    def individual_forward(x, net, bias):
        """
        Forward pass of an individual, simulating the layer activation. Used for evaluation.
        """
        relu = torch.nn.ReLU()
        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)
        return relu(torch.mm(x_direction, net.T) + bias.unsqueeze(0))


def create_torch_stats():
    """
    Create the statistics for the genetic algorithm
    """
    stats = tools.Statistics(key=lambda ind: ind.fitness.values)
    stats.register("avg", stat_on_tensor, np.mean)
    stats.register("std", stat_on_tensor, np.std)
    stats.register("min", stat_on_tensor, np.min)
    stats.register("max", stat_on_tensor, np.max)
    return stats


def stat_on_tensor(op, *args):
    """ Apply a numpy operation on a tensor """
    return op([arg.cpu().detach().numpy() for arg, in args[0]])


def plot_res(logbook):
    """ Plot the results of the genetic algorithm"""
    gen = logbook.select("gen")

    fig, ax = plt.subplots()
    #ax.plot(gen, logbook.select("avg"), "r-", label="Average Size")
    ax.plot(gen, logbook.select("max"), "b-", label="Maximum Fitness")
    #ax.plot(gen, logbook.select("min"), "g-", label="Minimum Fitness")
    ax.legend()


def print_net_error(net, test_loader, device, print_all_class=False):
    """ Print the test error of the network """
    x_te, y_te = next(iter(test_loader))
    x_te, y_te = x_te.to(device), y_te.to(device)
    print('test error:', 1.0 - net.predict(x_te).eq(y_te).float().mean().item())

    if print_all_class:
        # get the indexes where y_te is 1
        for i in range(10):
            idx = y_te.eq(i).nonzero().squeeze(1)
            print(f'test error for digit {i}:', 1.0 - net.predict(x_te[idx]).eq(y_te[idx]).float().mean().item())

def reset_seed():
    """ Reset the seed of all random number generators """
    torch.manual_seed(0)
    torch.mps.manual_seed(0)
    np.random.seed(0)
    random.seed(0)
    torch.use_deterministic_algorithms(True)


class TorchHallOfFame(tools.HallOfFame):
    """
    Hall of fame for the genetic algorithm. It is used to store the best individuals.
    It is a modified version of the HallOfFame class of the DEAP library.
    I needed to modify it because the legacy uses deepcopy, which is not supported by pytorch.
    """
    def __init__(self, ind_init, maxsize=0, similar=np.array_equal):
        super().__init__(maxsize, similar)
        self.ind_init = ind_init

    def insert(self, item):
        item2 = item.clone().detach()
        i = bisect_right(self.keys, item.fitness)
        ind = self.ind_init(item2)
        ind.fitness = item.fitness
        self.items.insert(len(self) - i, ind)
        self.keys.insert(i, ind)

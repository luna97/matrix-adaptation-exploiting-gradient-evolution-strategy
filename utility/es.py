from deap import base, creator, tools, algorithms
import math
import torch
import numpy as np
import random
from scipy.special import gamma
from joblib import Parallel, delayed
import joblib
import dill


# Vanilla LMMAES algorithm
class LMMAES(object):
    """
    LMMAES algorithm: this algorithm implements the LMMAES algorithm
    Low Memory Matrix Adaptation Evolution Strategy proposed in the paper:
    "Large Scale Black-Box Optimization by Limited-Memory Matrix Adaptation"
    Here is the link: https://ieeexplore.ieee.org/document/8410043
    """
    def __init__(
            self,
            n,
            lambda_=None,
            mu=None,
            m=None,
            sigma=None,
            device='cpu',
            starting_point=None,
    ):
        """
        Initialize the LMMAES algorithm
        :param n: number of dimensions of the problem
        :param lambda_: number of generated offsprings
        :param mu: number of selected individuals
        :param m: number of vectors that will approximate the covariance matrix
        :param sigma: learning rate
        :param device: device to use for torch
        :param starting_point: starting point of the algorithm, default is a vector of size n with values from a normal distribution
        """
        # device to use
        self.device = device

        # number of parameters
        self.n = n

        # number of generated offsprings
        # default: 4 + 3*ln(n)
        self.lambda_ = lambda_ if lambda_ is not None else 4 + int(math.floor(3 * math.log(n)))

        # number of selected individuals
        # default: lambda/2
        self.mu = mu if mu is not None else int(math.floor(self.lambda_ / 2))

        # weight vector initialization assigned to each selected individual
        # default: log(mu+1/2)-log(i) for i=1,...,mu
        denominator = sum([math.log(self.mu + 1 / 2) - math.log(j + 1) for j in range(self.mu)])
        self.w = torch.tensor([(math.log(self.mu + 1 / 2) - math.log(i + 1)) / denominator for i in range(self.mu)]).to(
            self.device)

        # mu_w vector initialization
        # weight assigned to all selected individual
        self.mu_w = 1 / torch.sum(self.w ** 2)

        # m parameter initialization -> default 4 + 3*ln(n)
        # number of vectors that will approximate the covariance matrix
        self.m = 4 + int(math.floor(3 * math.log(n))) if m is None else m

        # c_sigma initialization -> default 2*lambda/n
        # parameter for the Cumulative Step Size Adaptation
        # controls the learning rate of the step size adaptation
        self.c_sigma = (self.lambda_ * 2) / self.n

        # c_d initialization
        # it is a weight vector exponentially decaying
        # to appy on every vector approximating the matrix M
        self.c_d = torch.tensor([1 / ((1.5 ** i) * self.n) for i in range(self.m)]).to(self.device)

        # c_c initialization
        self.c_c = torch.tensor([self.lambda_ / ((4 ** i) * self.n) for i in range(self.m)]).to(self.device)

        # init centroid vector
        # init to a zero vector
        if starting_point is None:
            self.y = torch.randn(self.n).float().to(self.device)
        else:
            self.y = starting_point

        # init sigma, this is my global learning rate
        self.sigma = sigma if sigma is not None else 0.1

        # init the evolution path vector p_sigma
        # it is an exponentially fading record of recent most successful steps
        self.p_sigma = torch.zeros(self.n).float().to(self.device)

        # init the vector esimating the covariance matrix
        self.M = torch.zeros((self.m, self.n)).float().to(self.device)

        # init vectors containing the offspring's direction vectors
        self.d = torch.zeros((self.lambda_, self.n)).float().to(self.device)

        # init vectors containing the offspring's randomness vectors
        self.z = torch.zeros((self.lambda_, self.n)).float().to(self.device)

        # init the number of iterations
        self.t = 0

    def generate(self, ind_init):
        """
        Generate a new population of individuals
        :param ind_init: function to initialize an individual
        :return: the new population
        """

        # z are lambda samples from a normal distribution
        population = []
        for i in range(self.lambda_):
            self.z[i] = self.create_z()
            # direction vector -> initialized as random
            self.d[i] = self.z[i].clone()
            # direction vector is updated with the previous m directions
            for j in range(min(self.t, self.m)):
                # if d and M has the same direction, similarity is high,
                # it means that the direction is good, and we can use
                # it to update the direction vector by that factor
                similarity = (self.M[j] @ self.d[i])
                self.d[i] = (1 - self.c_d[j]) * self.d[i] + self.c_d[j] * self.M[j] * similarity

            # creating the individual
            # d[i] is now the mutation given by N(0, C) where C is the covariance matrix
            ind = (self.y + self.sigma * self.d[i]).detach()

            population.append(ind_init(ind.to(self.device)))
        return population

    def get_sorted_idx(self, population):
        """
        Get the ordered list of the indexes of the individuals, ordered by fitness
        :param population: population of individuals
        :return: the ordered list of the indexes of the individuals, ordered by fitness
        """
        fitness_list = [x.fitness for x in population]
        # get the ordered list of the indexes of the mu best individuals
        sorted_idx = [i for _, i in sorted(zip(fitness_list, range(len(fitness_list))), reverse=True)][0:self.mu]
        return sorted_idx

    def update(self, population):
        """
        Update the parameters of the algorithm
        :param population: generated population, already evaluated
        """

        # get the ordered list of the indexes of the mu best individuals
        sorted_idx = self.get_sorted_idx(population)
        # calculate the weighted sum of the mu best individuals
        weighted_d = torch.zeros((self.mu, self.n)).float().to(self.device)
        weighted_z = torch.zeros((self.mu, self.n)).float().to(self.device)

        j = 0
        for i in sorted_idx:
            weighted_d[j] = self.w[j] * self.d[i]
            weighted_z[j] = self.w[j] * self.z[i]
            j += 1

        # update the evolution path of the best solutions
        self.p_sigma = (1 - self.c_sigma) * self.p_sigma \
                       + torch.sqrt(self.mu_w * self.c_sigma * (2 - self.c_sigma)) \
                       * torch.sum(weighted_z, dim=0)

        # update the support vectors for the covariacne matrix
        for i in range(self.m):
            self.M[i] = (1 - self.c_c[i]) * self.M[i] \
                        + torch.sqrt(self.mu_w * self.c_c[i] * (2 - self.c_c[i])) \
                        * torch.sum(weighted_z, dim=0)

        # update sigma
        self.sigma = self.sigma * torch.exp(((torch.norm(self.p_sigma) ** 2 / self.n) - 1) * self.c_sigma / 2)

        # calculate new centroid
        self.y = self.y + self.sigma * torch.sum(weighted_d, dim=0)

        # update the number of iterations
        self.t += 1

    def create_z(self):
        """
        Create a new noise vector
        :return: the noise vector
        """
        return torch.randn(self.n).float().to(self.device)


class LMMAEGES(LMMAES):
    """
    LMMA-EG-ES algorithm: this aglorithm is a modification of the LMMA-ES algorithm
    Low Memory Matrix Adaptation with Estimated Gradient Evolution Strategy
    where I will exploit the information of the gradient.
    You can use the real gradient or an estimated one for when the gradient is not available.
    It uses the gradient information to compute an ADAM-like update of the parameters.
    It can use the Lévy flight in the creation of the noise vectors.
    """

    def __init__(
            self,
            n,
            evaluator,
            lambda_=None,
            mu=None,
            m=None,
            sigma=None,
            device='cpu',
            scale=1.0,
            beta1=0.9,
            beta2=0.999,
            epsilon=1e-8,
            weight_decay=0,
            use_levy_flight=True,
            use_real_gradient=False,
            momentum_strategy='mom',
            starting_point=None,
    ):
        """
        Initialize the LMM-EG-ES algorithm
        :param n: number of dimensions of the problem
        :param lambda_: number of generated offsprings
        :param mu: number of selected individuals
        :param m: number of vectors that will approximate the covariance matrix
        :param sigma: learning rate
        :param device: device to use for torch
        :param beta1: beta1 parameter of ADAM
        :param beta2: beta2 parameter of ADAM
        :param epsilon: epsilon parameter of ADAM
        :param weight_decay: weight decay parameter of ADAM
        :param use_levy_flight: tells if to use Lévy flight or not
        :param use_real_gradient: tells if to use the real gradient or not
        :param momentum_strategy: tells which momentum strategy to use, 'mom' or 'adam'
        :param starting_point: starting point of the algorithm, default is a vector of size n with values from a normal distribution

        """
        super().__init__(n=n, lambda_=lambda_, mu=mu, m=m, sigma=sigma, device=device, starting_point=starting_point)

        # tells if to use Lévy flight or not
        self.loss = None
        self.old_loss = None
        self.use_levy_flight = use_levy_flight
        self.scale = scale
        self.momentum_strategy = momentum_strategy

        # evaluator
        self.evaluator = evaluator

        # tells if to use the real gradient or not
        self.use_real_gradient = use_real_gradient

        # init adam parameters
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        self.weight_decay = weight_decay

        # init the momentum and velocity vector
        self.momentum = torch.zeros(self.n).float().to(device)
        self.velocity = torch.zeros(self.n).float().to(device)
        self.gradient = None
        self.v_hat_max = - torch.ones(self.n).float().to(device) * math.inf

        # if we use the real gradient, we need to keep track
        # of the torch graph to compute the gradient
        if self.use_real_gradient:
            self.y = self.y.requires_grad_(True)
            self.y.retain_grad()

        self.step = 0

    def update(self, population):
        """
        Update the parameters of the algorithm
        :param population: generated population, already evaluated
        """
        super().update(population)
        sorted_idx = self.get_sorted_idx(population)

        self.step += 1

        if self.use_real_gradient:
            self.y = self.y.detach().clone()
            self.y = self.y.requires_grad_(True)
            self.y.retain_grad()

        # calculate the gradient using the mu best individuals
        self.calculate_grad([p for i, p in enumerate(population) if i in sorted_idx])

    def create_z(self):
        """
        Create a new noise vector
        :return: the new noise vector
        """
        z = super().create_z()
        if self.gradient is None:
            return z
        else:
            # get a copy of the gradient
            gradient = self.gradient.clone().detach()

            # scale the gradient
            # gradient = gradient / gradient.norm()
            gradient = gradient * self.scale

            # apply levy flight to the gradient
            # levy flight gives the weight to the gradient
            if self.use_levy_flight:
                gradient = gradient * abs(levy_flight(1))

            # add the noise to the gradient
            grad_noised = gradient + z

            # normalize the gradient
            grad_noised = grad_noised / grad_noised.std()

            return grad_noised

    def calculate_grad(self, population):
        """
        Calculate the estimation gradient or the real one for the loss function
        :param population: population to use to calculate the gradient
        """
        self.old_loss = self.loss
        self.loss = self.evaluator.evaluate(self.y)[0]

        if self.use_real_gradient:
            # torch automatically computes the gradient
            self.loss.backward()
            gradient = self.y.grad.detach().clone()
        elif population is not None:
            tmp = torch.zeros((self.lambda_, self.n), device=self.device)
            for i, p in enumerate(population):
                # calculate the direction from the centroid to the individual
                direction = self.y - p

                # calculate the loss difference
                loss_diff = self.loss - p.fitness.values[0]

                # calculate the gradient, penalizing for distant individuals
                tmp[i] = direction * loss_diff / (torch.norm(direction) ** 2)

            gradient = torch.mean(tmp, dim=0)

        if self.momentum_strategy == 'adam':
            # apply adam algorithm
            gradient = gradient + self.weight_decay * self.y.detach().clone()

            self.momentum = self.beta1 * self.momentum + (1 - self.beta1) * gradient
            self.velocity = self.beta2 * self.velocity + (1 - self.beta2) * gradient ** 2

            momentum_hat = self.momentum / (1 - self.beta1 ** (self.t + 1))
            velocity_hat = self.velocity / (1 - self.beta2 ** (self.t + 1))
            self.v_hat_max = torch.maximum(self.v_hat_max, velocity_hat)

            self.gradient = - momentum_hat / (torch.sqrt(self.v_hat_max) + self.epsilon)

        else:
            # apply momentum algorithm
            self.momentum = self.beta1 * self.momentum + (1 - self.beta1) * gradient
            self.gradient = -self.momentum


def levy_flight(beta, scale=1.0):
    """
    Generate a random step length following a Levy distribution.
    :param beta: The tail index of the Levy distribution (typically between 1 and 2).
    :param scale: Scaling factor to control the step size.
    :return: A random step length.
    """
    sigma_u = (
                      gamma(1 + beta) * np.sin(np.pi * beta / 2)
                      / (
                              gamma((1 + beta) / 2) *
                              beta * 2 ** ((beta - 1) / 2)
                      )
              ) ** (1 / beta)
    sigma_v = 1

    u = np.random.normal(0, sigma_u)
    v = np.random.normal(0, sigma_v)

    step = u / (abs(v) ** (1 / beta))

    return scale * step


def eaGenerateUpdateBatched(toolbox, loader, ngen, halloffame=None, stats=None, run_parallel=False, verbose=__debug__):
    """
    This function is a modified version of the eaGenerateUpdate function of the DEAP library.
    It is used to train the network in a batched way. At every generation, the network is trained on a different batch
    :param toolbox: toolbox
    :param loader: the dataloader with positive and negative examples
    :param ngen: number of generations
    :param halloffame: hall of fame object
    :param stats: statistics recorder
    :param verbose: tell if the function should print the statistics
    :return: the final population and the logbook
    """
    logbook = tools.Logbook()
    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])

    # combine dataloaders

    step = 0

    for _ in range(ngen):
        for x_pos, x_neg in loader:
            if step >= ngen:
                break

            toolbox.set_batch(x_pos, x_neg)

            # Generate a new population
            population = toolbox.generate()

            if run_parallel:
                # Parallel evaluation of individuals
                fitnesses = Parallel(n_jobs=-1)(delayed(toolbox.evaluate)(ind) for ind in population)

                for ind, fit in zip(population, fitnesses):
                    ind.fitness.values = fit

            else:
                # Evaluate the individuals
                fitnesses = toolbox.map(toolbox.evaluate, population)
                for ind, fit in zip(population, fitnesses):
                    ind.fitness.values = fit

            # Update the hall of fame with the generated individuals
            if halloffame is not None:
                halloffame.update(population)

            # Update the strategy with the evaluated individuals
            toolbox.update(population)

            # Append the current generation statistics to the logbook
            record = stats.compile(population) if stats is not None else {}
            logbook.record(gen=step, nevals=len(population), **record)
            if verbose:
                print(logbook.stream)

            step += 1

    return population, logbook